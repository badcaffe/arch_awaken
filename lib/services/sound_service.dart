import 'dart:async';
import 'dart:io';
import 'package:just_audio_ohos/just_audio_ohos.dart';
import 'package:audio_session/audio_session.dart';

// Abstract class to define the audio interface
abstract class _AudioPlayerInterface {
  Future<void> play([dynamic source]);
  Future<void> stop();
  Future<void> setVolume(double volume);
  Future<void> setAudioSource(dynamic source);
  void dispose();
  Stream get onPlayerStateChanged;
  Stream get onPlayerComplete;
}

// Platform-specific implementations
class _SoundService {
  _AudioPlayerInterface? _player;
  bool _isAudioSupported = true;
  bool _isInitialized = false;
  Completer<void>? _initCompleter;

  _SoundService() {
    // Don't initialize immediately - do lazy initialization
    _isInitialized = false;
  }

  /// Lazy initialization - only initialize when first needed
  Future<void> _ensureInitialized() async {
    // If already initialized, return immediately
    if (_isInitialized && _initCompleter == null) {
      return;
    }

    // If initialization is in progress, wait for it with timeout
    if (_initCompleter != null) {
      try {
        await _initCompleter!.future.timeout(const Duration(seconds: 10));
      } catch (e) {
        print('âš ï¸ Initialization timeout: $e');
        // Mark as initialized anyway to avoid hanging
        _isInitialized = true;
      }
      return;
    }

    // Start initialization
    _initCompleter = Completer<void>();
    try {
      await _initializeAudio().timeout(const Duration(seconds: 10));
      _isInitialized = true;
      _initCompleter!.complete();
      print('âœ… Audio initialization completed');
    } catch (e) {
      print('âŒ Audio initialization failed: $e');
      _isInitialized = true; // Mark as initialized to avoid hanging
      _isAudioSupported = false;
      _player = _NoOpAudioPlayer();
      _initCompleter!.completeError(e);
    } finally {
      _initCompleter = null;
    }
  }

  /// Platform detection: Check if running on HarmonyOS
  Future<bool> _isHarmonyOS() async {
    // Check 1: Platform operating system name
    if (Platform.operatingSystem.toLowerCase() == 'harmonyos') {
      print('âœ… Detected HarmonyOS via Platform.operatingSystem');
      return true;
    }

    // Check 2a: System properties for HarmonyOS (if running on Android device)
    if (Platform.operatingSystem == 'android') {
      try {
        final result = await Process.run('getprop', ['ro.build.harmonyos']);
        if (result.exitCode == 0) {
          final output = result.stdout.toString().trim();
          if (output.isNotEmpty && output != '0' && output != 'false') {
            print('âœ… Detected HarmonyOS via getprop: $output');
            return true;
          }
        }
      } catch (e) {
        // getprop command not available
      }

      // Check 2b: OS version string
      final version = Platform.operatingSystemVersion.toLowerCase();
      if (version.contains('harmonyos') || version.contains('harmony')) {
        print('âœ… Detected HarmonyOS via version string');
        return true;
      }
    }

    // Platform is likely supported with just_audio
    return false;
  }

  Future<void> _initializeAudio() async {
    try {
      // Use just_audio_ohos for all platforms (works on HarmonyOS and should be compatible)
      _player = _JustAudioPlayerOhosImpl();
      print('âœ… Audio initialized with just_audio_ohos');
      _isAudioSupported = true;
    } catch (e) {
      print('âš ï¸ Audio initialization failed: $e');
      _isAudioSupported = false;
      _player = _NoOpAudioPlayer();
    }

    _isInitialized = true;
  }

  /// Configure audio session for proper audio playback
  Future<void> _configureAudioSession() async {
    try {
      // Configure audio session with appropriate category and options
      final session = await AudioSession.instance;
      await session.configure(const AudioSessionConfiguration.speech());
      print('ğŸ”Š Audio session configured');

      // On HarmonyOS, we might need to activate the session differently
      final isHarmonyOS = await _isHarmonyOS();
      if (isHarmonyOS) {
        print('ğŸ”Š HarmonyOS detected - activating audio session');
        try {
          await session.setActive(true);
          print('ğŸ”Š Audio session activated for HarmonyOS');
        } catch (e) {
          print('âš ï¸ Failed to activate session on HarmonyOS: $e');
        }
      }
    } catch (e) {
      print('âš ï¸ Audio session configuration failed: $e');
      // Continue without audio session - just_audio will still work
    }
  }

  /// æ’­æ”¾æ•°å­—å£°éŸ³æ–‡ä»¶
  Future<void> playNumberSound(int number) async {
    await _ensureInitialized();
    final soundPath = 'assets/sounds/num_$number.mp3';
    await _playSound(soundPath);
  }

  /// æ’­æ”¾å€’è®¡æ—¶å£°éŸ³
  Future<void> playCountdownSound() async {
    await _ensureInitialized();
    const soundPath = 'assets/sounds/gear.mp3';
    await _playSound(soundPath);
  }

  /// æ’­æ”¾å®Œæˆå£°éŸ³
  Future<void> playCheerSound() async {
    await _ensureInitialized();
    const soundPath = 'assets/sounds/cheer.mp3';
    await _playSound(soundPath);
  }

  /// æ’­æ”¾å’•å˜Ÿå£°éŸ³ï¼ˆä¼‘æ¯ä¸­è®¡æ—¶ï¼‰
  Future<void> playGuduSound() async {
    await _ensureInitialized();
    const soundPath = 'assets/sounds/gudu.mp3';
    await _playSound(soundPath);
  }

  /// æ’­æ”¾ä¼‘æ¯å¼€å§‹å£°éŸ³
  Future<void> playRestStartSound() async {
    await _ensureInitialized();
    const soundPath = 'assets/sounds/rest-start.mp3';
    await _playSound(soundPath);
  }

  /// æ’­æ”¾å¼€å§‹å£°éŸ³
  Future<void> playStartSound() async {
    await _ensureInitialized();
    const soundPath = 'assets/sounds/start.mp3';
    await _playSound(soundPath);
  }

  /// æ’­æ”¾ä¼‘æ¯ç»“æŸå£°éŸ³
  Future<void> playRestEndSound() async {
    await _ensureInitialized();
    const soundPath = 'assets/sounds/rest-end.mp3';
    await _playSound(soundPath);
  }

  /// æ’­æ”¾æ‰€æœ‰è®­ç»ƒå®Œæˆå£°éŸ³
  Future<void> playAllDoneSound() async {
    await _ensureInitialized();
    const soundPath = 'assets/sounds/all_done.mp3';
    await _playSound(soundPath);
  }

  /// æ’­æ”¾è‡ªå®šä¹‰å£°éŸ³æ–‡ä»¶
  Future<void> playCustomSound(String soundPath) async {
    await _ensureInitialized();
    await _playSound(soundPath);
  }

  /// æµ‹è¯•éŸ³é¢‘æ’­æ”¾ - ç”¨äºè°ƒè¯•
  Future<void> testAudioPlayback() async {
    print('ğŸ§ª å¼€å§‹éŸ³é¢‘æµ‹è¯•...');
    await _ensureInitialized();

    // Test with a simple sound
    const testPath = 'assets/sounds/gear.mp3';
    print('ğŸ§ª æµ‹è¯•æ’­æ”¾: $testPath');

    try {
      await _playSound(testPath);
      print('ğŸ§ª éŸ³é¢‘æµ‹è¯•å®Œæˆ');
    } catch (e) {
      print('ğŸ§ª éŸ³é¢‘æµ‹è¯•å¤±è´¥: $e');
    }
  }

  /// è·å–è¯¦ç»†éŸ³é¢‘çŠ¶æ€ä¿¡æ¯
  Future<Map<String, dynamic>> getAudioStatus() async {
    final status = <String, dynamic>{};

    try {
      final playerImpl = _player as _JustAudioPlayerOhosImpl;
      final player = playerImpl._player;
      status['isAudioSupported'] = _isAudioSupported;
      status['platform'] = Platform.operatingSystem;
      status['processingState'] = player.processingState.toString();
      status['playing'] = player.playing;
      status['volume'] = player.volume;
      status['speed'] = player.speed;
      status['position'] = player.position.inMilliseconds;
      status['duration'] = player.duration?.inMilliseconds;
    } catch (e) {
      status['error'] = e.toString();
    }

    return status;
  }

  /// æ’­æ”¾å£°éŸ³çš„é€šç”¨æ–¹æ³•
  Future<void> _playSound(String soundPath) async {
    if (!_isAudioSupported || _player == null) {
      print('ğŸ”‡ Audio not supported on this platform: $soundPath');
      return;
    }

    try {
      // ä½¿ç”¨åŒä¸€ä¸ªAudioPlayerå®ä¾‹ï¼Œä½†å…ˆåœæ­¢å½“å‰æ’­æ”¾çš„å£°éŸ³
      await _player!.stop();

      // Create the asset source
      final assetSource = AudioSource.asset(soundPath);

      print('ğŸ”Š æ’­æ”¾éŸ³é¢‘: $soundPath');

      // Load the audio source
      print('ğŸ”„ Loading audio source...');
      await _player!.setAudioSource(assetSource);
      print('âœ… Audio source loaded');

      // Wait a moment for the duration to be available
      final playerImpl = _player as _JustAudioPlayerOhosImpl;
      final player = playerImpl._player;
      int waitCount = 0;
      while (player.duration == null && waitCount < 50) {
        await Future.delayed(const Duration(milliseconds: 100));
        waitCount++;
      }

      if (player.duration != null) {
        print('âœ… Audio duration available: ${player.duration!.inMilliseconds}ms');
      } else {
        print('âš ï¸ Audio duration not available after 5 seconds');
      }

      // Set volume to maximum for debugging
      await _player!.setVolume(1.0);
      print('ğŸ”Š Volume set to: 1.0');

      print('â–¶ï¸ Starting playback...');
      await _player!.play();

      // ç›‘å¬æ’­æ”¾çŠ¶æ€
      _player!.onPlayerStateChanged.listen((state) {
        print('ğŸ”Š éŸ³é¢‘çŠ¶æ€: $state for $soundPath');
      });

      _player!.onPlayerComplete.listen((_) {
        print('ğŸ”Š éŸ³é¢‘æ’­æ”¾å®Œæˆ: $soundPath');
      });

      // Log player details for debugging
      _logPlayerDetails();

    } catch (e) {
      print('âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥: $soundPath, é”™è¯¯: $e');
      print('âŒ é”™è¯¯è¯¦æƒ…: ${e.runtimeType}');
      print('âŒ Stack trace: ${StackTrace.current}');
      _isAudioSupported = false;
      _player = _NoOpAudioPlayer();
    }
  }

  /// Log detailed player information for debugging
  Future<void> _logPlayerDetails() async {
    try {
      final playerImpl = _player as _JustAudioPlayerOhosImpl;
      final player = playerImpl._player;
      final processingState = player.processingState;
      final playing = player.playing;
      final volume = player.volume;
      final speed = player.speed;
      final position = player.position;
      final duration = player.duration;

      print('ğŸ“Š Player State Debug:');
      print('   Processing State: $processingState');
      print('   Playing: $playing');
      print('   Volume: $volume (0.0-1.0)');
      print('   Speed: $speed');
      print('   Position: $position');
      print('   Duration: $duration');

      if (duration != null) {
        print('   Duration in seconds: ${duration.inSeconds}s');
      }
    } catch (e) {
      print('âš ï¸ Failed to log player details: $e');
    }
  }

  /// Request audio focus before playing audio
  Future<void> _requestAudioFocus() async {
    try {
      final session = await AudioSession.instance;
      print('ğŸ”Š Requesting audio focus...');
      final result = await session.setActive(true);
      if (result) {
        print('ğŸ”Š âœ… Audio focus acquired successfully');
      } else {
        print('âš ï¸ âš ï¸ Failed to acquire audio focus (returned false)');
      }

      // Log current audio mode
      try {
        final androidAudioMode = session.androidAudioAttributes;
        print('ğŸ”Š Android audio attributes: $androidAudioMode');
      } catch (e) {
        // Not on Android, that's ok
      }
    } catch (e) {
      print('âš ï¸ Audio focus request failed: $e');
      // Continue without audio focus - some systems may not require it
    }
  }

  /// åœæ­¢æ‰€æœ‰æ­£åœ¨æ’­æ”¾çš„å£°éŸ³
  Future<void> stopAllSounds() async {
    if (_isAudioSupported && _player != null) {
      await _player!.stop();
    }
  }

  /// é‡Šæ”¾æ‰€æœ‰èµ„æº
  void dispose() {
    if (_player != null) {
      _player!.dispose();
    }
  }

  /// æ£€æŸ¥éŸ³é¢‘æ˜¯å¦æ”¯æŒ
  bool get isAudioSupported => _isAudioSupported;
}

// No-op implementation for platforms without audio support
class _NoOpAudioPlayer implements _AudioPlayerInterface {
  @override
  Future<void> play([source]) async {}

  @override
  Future<void> stop() async {}

  @override
  Future<void> setVolume(double volume) async {}

  @override
  Future<void> setAudioSource(source) async {}

  @override
  void dispose() {}

  @override
  Stream get onPlayerStateChanged => const Stream.empty();

  @override
  Stream get onPlayerComplete => const Stream.empty();
}

// Just Audio implementation for HarmonyOS (using just_audio_ohos)
class _JustAudioPlayerOhosImpl implements _AudioPlayerInterface {
  final AudioPlayer _player;

  _JustAudioPlayerOhosImpl()
      : _player = AudioPlayer(),
        super() {
    // Initialize HarmonyOS-specific player
    print('ğŸ”Š Initializing HarmonyOS audio player...');
  }

  @override
  Future<void> play([dynamic source]) async {
    if (source != null) {
      await _player.setAudioSource(source);
    }
    await _player.play();
    print('ğŸ”Š HarmonyOS audio playback started');
  }

  @override
  Future<void> stop() async {
    await _player.stop();
    print('ğŸ”Š HarmonyOS audio playback stopped');
  }

  @override
  Future<void> setVolume(double volume) async {
    await _player.setVolume(volume);
    print('ğŸ”Š HarmonyOS audio volume set to: $volume');
  }

  @override
  Future<void> setAudioSource(dynamic source) async {
    await _player.setAudioSource(source);
    print('ğŸ”Š HarmonyOS audio source set: $source');
  }

  @override
  void dispose() {
    _player.dispose();
    print('ğŸ”Š HarmonyOS audio player disposed');
  }

  @override
  Stream get onPlayerStateChanged {
    return _player.playerStateStream.map((state) {
      // Convert just_audio_ohos state to our format
      switch (state.processingState) {
        case ProcessingState.idle:
        case ProcessingState.loading:
          return 'loading';
        case ProcessingState.buffering:
          return 'buffering';
        case ProcessingState.ready:
          return 'playing';
        case ProcessingState.completed:
          return 'completed';
      }
    });
  }

  @override
  Stream get onPlayerComplete {
    return _player.playerStateStream.where((state) {
      return state.processingState == ProcessingState.completed;
    }).map((_) => null);
  }
}

// SoundService public interface - delegates to the appropriate implementation
class SoundService {
  static SoundService? _instance;
  static final _SoundService _delegate = _SoundService();

  // Singleton pattern to avoid creating multiple instances
  factory SoundService() {
    _instance ??= SoundService._();
    return _instance!;
  }

  SoundService._();

  /// æ’­æ”¾æ•°å­—å£°éŸ³æ–‡ä»¶
  Future<void> playNumberSound(int number) => _delegate.playNumberSound(number);

  /// æ’­æ”¾å€’è®¡æ—¶å£°éŸ³
  Future<void> playCountdownSound() => _delegate.playCountdownSound();

  /// æ’­æ”¾å®Œæˆå£°éŸ³
  Future<void> playCheerSound() => _delegate.playCheerSound();

  /// æ’­æ”¾å’•å˜Ÿå£°éŸ³ï¼ˆä¼‘æ¯ä¸­è®¡æ—¶ï¼‰
  Future<void> playGuduSound() => _delegate.playGuduSound();

  /// æ’­æ”¾ä¼‘æ¯å¼€å§‹å£°éŸ³
  Future<void> playRestStartSound() => _delegate.playRestStartSound();

  /// æ’­æ”¾å¼€å§‹å£°éŸ³
  Future<void> playStartSound() => _delegate.playStartSound();

  /// æ’­æ”¾ä¼‘æ¯ç»“æŸå£°éŸ³
  Future<void> playRestEndSound() => _delegate.playRestEndSound();

  /// æ’­æ”¾æ‰€æœ‰è®­ç»ƒå®Œæˆå£°éŸ³
  Future<void> playAllDoneSound() => _delegate.playAllDoneSound();

  /// æ’­æ”¾è‡ªå®šä¹‰å£°éŸ³æ–‡ä»¶
  Future<void> playCustomSound(String soundPath) => _delegate.playCustomSound(soundPath);

  /// æµ‹è¯•éŸ³é¢‘æ’­æ”¾ - ç”¨äºè°ƒè¯•
  Future<void> testAudioPlayback() => _delegate.testAudioPlayback();

  /// è·å–è¯¦ç»†éŸ³é¢‘çŠ¶æ€ä¿¡æ¯
  Future<Map<String, dynamic>> getAudioStatus() => _delegate.getAudioStatus();

  /// åœæ­¢æ‰€æœ‰æ­£åœ¨æ’­æ”¾çš„å£°éŸ³
  Future<void> stopAllSounds() => _delegate.stopAllSounds();

  /// é‡Šæ”¾æ‰€æœ‰èµ„æº
  void dispose() => _delegate.dispose();

  /// æ£€æŸ¥éŸ³é¢‘æ˜¯å¦æ”¯æŒ
  bool get isAudioSupported => _delegate.isAudioSupported;
}
